{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    parsed_file = \"data/movies_parsed.csv\"\n",
    "    # raw_file = \"data/movies_raw.csv\"  # Update with actual raw data path\n",
    "\n",
    "    if os.path.exists(parsed_file):\n",
    "        return pd.read_csv(parsed_file)\n",
    "    else:\n",
    "\n",
    "        # -------------------------------\n",
    "        # Step 1: Load the Datasets\n",
    "        # -------------------------------\n",
    "        # Load movies metadata. Use low_memory=False to avoid dtype warnings.\n",
    "        movies_df = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "        # Load keywords and credits\n",
    "        keywords_df = pd.read_csv('data/keywords.csv')\n",
    "        credits_df = pd.read_csv('data/credits.csv')\n",
    "\n",
    "        return clean_and_parse(movies_df, keywords_df, credits_df)\n",
    "\n",
    "\n",
    "def clean_and_parse(movies_df: pd.DataFrame, keywords_df: pd.DataFrame, credits_df: pd.DataFrame):\n",
    "    # -------------------------------\n",
    "    # Step 2: Clean the Movies Metadata\n",
    "    # -------------------------------\n",
    "    # The movies_metadata 'id' column contains some non-numeric values.\n",
    "    # Remove rows where 'id' is not numeric and convert the rest to integers.\n",
    "    movies_df = movies_df[movies_df['id'].apply(lambda x: str(x).isdigit())]\n",
    "    movies_df['id'] = movies_df['id'].astype(int)\n",
    "\n",
    "    # Optionally, you can drop rows with missing overviews:\n",
    "    movies_df['overview'] = movies_df['overview'].fillna('')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 3: Merge Datasets\n",
    "    # -------------------------------\n",
    "    # Merge movies_df with keywords_df and credits_df on the 'id' column.\n",
    "    movies_df = movies_df.merge(keywords_df, on='id', how='left')\n",
    "    movies_df = movies_df.merge(credits_df, on='id', how='left')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 4: Convert Stringified Lists to Python Lists\n",
    "    # -------------------------------\n",
    "    def parse_features(x):\n",
    "        \"\"\"\n",
    "        Convert a stringified list of dictionaries into a list of names.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lst = ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "        return [item['name'] for item in lst]\n",
    "\n",
    "    # Convert genres and keywords columns\n",
    "    movies_df['genres'] = movies_df['genres'].apply(parse_features)\n",
    "    movies_df['keywords'] = movies_df['keywords'].apply(parse_features)\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 5: Process the Cast and Crew\n",
    "    # -------------------------------\n",
    "    def parse_cast(x):\n",
    "        \"\"\"\n",
    "        Extract the first three cast members (if available).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lst = ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "        # Return the names of the top 3 cast members\n",
    "        return [item['name'] for item in lst][:3]\n",
    "\n",
    "    def get_director(x):\n",
    "        \"\"\"\n",
    "        Extract the director's name from the crew list.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lst = ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return \"\"\n",
    "        for item in lst:\n",
    "            if item.get('job') == 'Director':\n",
    "                return item.get('name', \"\")\n",
    "        return \"\"\n",
    "\n",
    "    # Process cast and crew columns\n",
    "    movies_df['cast'] = movies_df['cast'].apply(parse_cast)\n",
    "    movies_df['director'] = movies_df['crew'].apply(get_director)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 6: Clean the Data\n",
    "    # -------------------------------\n",
    "    def clean_data(x):\n",
    "        \"\"\"\n",
    "        Lowercase and remove spaces from strings (or elements of lists).\n",
    "        \"\"\"\n",
    "        if isinstance(x, list):\n",
    "            return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "        elif isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    movies_df['genres'] = movies_df['genres'].apply(clean_data)\n",
    "    movies_df['keywords'] = movies_df['keywords'].apply(clean_data)\n",
    "    movies_df['cast'] = movies_df['cast'].apply(clean_data)\n",
    "    movies_df['director'] = movies_df['director'].apply(clean_data)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 7: Create a 'Soup' of Features\n",
    "    # -------------------------------\n",
    "    # The \"soup\" is a string that contains all relevant features which we later vectorize.\n",
    "    def create_soup(x):\n",
    "        \"\"\"\n",
    "        Create a soup of features for each movie.\n",
    "        \"\"\"\n",
    "        keywords = ' '.join(x['keywords'])\n",
    "        genres = ' '.join(x['genres'])\n",
    "        cast = ' '.join(x['cast'])\n",
    "        director = x['director']\n",
    "        overview = x['overview']\n",
    "        \n",
    "        # Combine all features into a single string\n",
    "        return f\"{keywords} {genres} {cast} {director} {overview}\".strip()\n",
    "\n",
    "    \n",
    "    movies_df['soup'] = movies_df.apply(create_soup, axis=1)\n",
    "    return movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11608/2358833907.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_df['id'] = movies_df['id'].astype(int)\n",
      "/tmp/ipykernel_11608/2358833907.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_df['overview'] = movies_df['overview'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "movies_df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limit number of rows\n",
    "movies_df = movies_df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Step 8: Create the Count Matrix and Compute Cosine Similarity\n",
    "# -------------------------------\n",
    "# Vectorize the text in the 'soup' column.\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(movies_df['soup'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Step 9: Build a Reverse Mapping from Movie Titles to DataFrame Indices\n",
    "# -------------------------------\n",
    "# Reset the index so that it aligns with our similarity matrix.\n",
    "movies_df = movies_df.reset_index(drop=True)\n",
    "indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Step 10: Create the Recommendation Function\n",
    "# -------------------------------\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    \"\"\"\n",
    "    Given a movie title, return the top 10 most similar movies.\n",
    "    \"\"\"\n",
    "    if title not in indices:\n",
    "        return f\"Movie '{title}' not found in the dataset.\"\n",
    "\n",
    "    idx = indices[title]\n",
    "    \n",
    "    # Get the pairwise similarity scores for this movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Sort movies based on similarity score (descending order)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Skip the first movie as it is the movie itself, then take the next 10.\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    \n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the top 10 most similar movies\n",
    "    return movies_df['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'The Godfather':\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m get_recommendations(movie_to_search)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_to_search\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrecommendations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Step 11: Test the Recommendation System\n",
    "# -------------------------------\n",
    "# Replace \"The Godfather\" with any movie title from the dataset.\n",
    "movie_to_search = \"The Godfather\"\n",
    "recommendations = get_recommendations(movie_to_search)\n",
    "\n",
    "print(f\"Recommendations for '{movie_to_search}':\")\n",
    "print(recommendations.to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
